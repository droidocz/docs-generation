{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gabriel.dutradias/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/gabriel.dutradias/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from utils import create_folder, cleanup_folder, human_to_kebab_case\n",
    "from comment_classifier.utils import preprocess_comment\n",
    "from comment_classifier.sentence_scorer import SentenceScorer\n",
    "from doc_page import TagDocPage, PostQuestionDocPage\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'output'\n",
    "n_questions_per_tag = 15\n",
    "redundant_tags = ['android']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_csv('data/comments.csv')\n",
    "posts_questions_df = pd.read_csv('data/posts_questions.csv').drop_duplicates(subset=['id'])\n",
    "posts_answers_df = pd.read_csv('data/posts_answers.csv')\n",
    "posts_tag_wiki_df = pd.read_csv('data/posts_tag_wiki.csv')\n",
    "posts_tag_wiki_excerpt_df = pd.read_csv('data/posts_tag_wiki_excerpt.csv')\n",
    "selected_tags_df = pd.read_csv('data/selected_tags.csv')\n",
    "tags_df = pd.read_csv('data/tags.csv')\n",
    "users_df = pd.read_csv('data/users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-compute important values for evaluation\n",
    "\n",
    "# add user reputation to post answers\n",
    "posts_answers_with_user_df = pd.merge(left=posts_answers_df, right=users_df[['reputation', 'id']].add_prefix('user_'), left_on='owner_user_id', right_on='user_id')\n",
    "\n",
    "# scale values\n",
    "scaler = MinMaxScaler()\n",
    "posts_questions_df[['scaled_view_count', 'scaled_score']] = scaler.fit_transform(posts_questions_df[['view_count', 'score']])\n",
    "posts_answers_with_user_df[['scaled_score', 'scaled_user_reputation']] = scaler.fit_transform(posts_answers_with_user_df[['score', 'user_reputation']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_answer(answer_row):\n",
    "    return statistics.mean([answer_row.scaled_score, answer_row.scaled_user_reputation])\n",
    "\n",
    "posts_answers_with_user_df['eval'] = posts_answers_with_user_df.apply(eval_answer, axis=1)\n",
    "\n",
    "def eval_question(question_row):\n",
    "    answer_rows = posts_answers_with_user_df.loc[posts_answers_with_user_df.parent_id == question_row.id].sort_values(by='eval', ascending=False)\n",
    "    if len(answer_rows) == 0:\n",
    "        return 0\n",
    "    answer_row = answer_rows.iloc[0]\n",
    "    return statistics.mean([question_row.scaled_view_count, question_row.scaled_score, answer_row.scaled_score, answer_row.scaled_user_reputation])\n",
    "\n",
    "posts_questions_df['eval'] = posts_questions_df.apply(eval_question, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare files and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_folder(output_dir)\n",
    "questions_for_docs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate docs for tags\n",
    "\n",
    "Docs for tags are based on the `posts_tag_wiki` table from Stackoverflow. Content should be a long description for what each tag represents as well as pointing out relevant complementary docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in selected_tags_df.iterrows():\n",
    "    tag_id = row.id\n",
    "    tag_name = row.tag_name\n",
    "    tag_description = posts_tag_wiki_excerpt_df.loc[posts_tag_wiki_excerpt_df.id == row.excerpt_post_id]['body'].values[0]\n",
    "    tag_wiki_body = posts_tag_wiki_df.loc[posts_tag_wiki_df.id == row.wiki_post_id]['body'].values[0]\n",
    "    # save tag doc page\n",
    "    TagDocPage(tag_name, tag_description, tag_wiki_body).save(f\"{output_dir}/{tag_name}.md\")\n",
    "\n",
    "    # prepare post questions for tag\n",
    "    create_folder(f\"{output_dir}/{tag_name}\")\n",
    "    tag_questions_df = posts_questions_df[posts_questions_df.tag_id == tag_id].copy()\n",
    "    selected_questions_df = tag_questions_df.sort_values(by='eval', ascending=False).head(n_questions_per_tag)\n",
    "    questions_for_docs.append(selected_questions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate docs for questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_docs_df = pd.concat(questions_for_docs)\n",
    "\n",
    "for idx, row in questions_for_docs_df.iterrows():\n",
    "    parent_tag_name = row.tag_name\n",
    "    question_title = row.title\n",
    "    question_body = row.body\n",
    "    question_tags = [tag for tag in row.tags.split('|') if tag not in redundant_tags and tag != row.tag_name]\n",
    "    \n",
    "    # select answer\n",
    "    question_answers_df = posts_answers_with_user_df[posts_answers_with_user_df.parent_id == row.id].copy()\n",
    "    selected_answer = question_answers_df.sort_values(by='eval', ascending=False).iloc[0]\n",
    "    comments = list(comments_df[comments_df.post_id == selected_answer.id].sort_values(by='score', ascending=False)['text'])\n",
    "    answer_body = selected_answer.body\n",
    "\n",
    "    # save post question doc page\n",
    "    output_file_name = human_to_kebab_case(question_title)\n",
    "    PostQuestionDocPage(question_title, question_body, question_tags, answer_body, comments).save(f\"{output_dir}/{parent_tag_name}/{output_file_name}.md\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
